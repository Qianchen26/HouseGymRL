{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HouseGym RL: Comprehensive Training and Evaluation Pipeline\n",
    "\n",
    "This notebook implements the full workflow:\n",
    "1. **Setup & Configuration**\n",
    "2. **Mechanism Verification** (10 verification cells)\n",
    "3. **SAC Training**\n",
    "4. **Cross-Scenario Evaluation**\n",
    "5. **Validation & Visualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1.1: Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# RL libraries\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, VecMonitor, VecNormalize\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback\n",
    "\n",
    "# Environment\n",
    "from housegymrl import RLEnv, BaselineEnv\n",
    "from config import REGION_CONFIG\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1.2: Create Output Directories\n",
    "output_dirs = [\n",
    "    \"results\",\n",
    "    \"results/figures\",\n",
    "    \"results/rmse\",\n",
    "    \"models\",\n",
    "    \"runs\",\n",
    "    \"runs/sac_diverse\",\n",
    "]\n",
    "\n",
    "for dir_path in output_dirs:\n",
    "    Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"‚úÖ Created/verified: {dir_path}\")\n",
    "\n",
    "print(\"\\n‚úÖ All output directories ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1.3: Configuration Summary\n",
    "print(\"=\"*70)\n",
    "print(\"CONFIGURATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "config = {\n",
    "    \"Environment\": {\n",
    "        \"M_ratio\": 0.10,\n",
    "        \"M_min\": 512,\n",
    "        \"M_max\": 2048,\n",
    "        \"stochastic_duration\": True,\n",
    "        \"observation_noise\": 0.15,\n",
    "        \"capacity_noise\": 0.10,\n",
    "        \"use_longterm_reward\": True,\n",
    "        \"use_batch_arrival\": True,\n",
    "        \"use_capacity_ramp\": True,\n",
    "    },\n",
    "    \"Training\": {\n",
    "        \"algorithm\": \"SAC\",\n",
    "        \"total_timesteps\": 500_000,\n",
    "        \"n_envs\": 8,\n",
    "        \"learning_rate\": 3e-4,\n",
    "        \"batch_size\": 512,\n",
    "    },\n",
    "    \"Evaluation\": {\n",
    "        \"test_regions\": [\"Mataram\", \"Sumbawa\", \"Central Lombok\"],\n",
    "        \"crew_levels\": [0.1, 0.3, 0.5, 0.7, 0.9, 1.0],\n",
    "        \"n_seeds\": 5,\n",
    "    }\n",
    "}\n",
    "\n",
    "for section, params in config.items():\n",
    "    print(f\"\\n{section}:\")\n",
    "    for key, val in params.items():\n",
    "        print(f\"  {key:25s}: {val}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Mechanism Verification\n",
    "\n",
    "Before training, we verify that all environment mechanisms work correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.1: Verify Adaptive M System\n",
    "print(\"=\"*70)\n",
    "print(\"VERIFICATION 1: ADAPTIVE M SYSTEM\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "test_env = RLEnv(\n",
    "    region_key=\"Mataram\",\n",
    "    M_ratio=0.10,\n",
    "    M_min=512,\n",
    "    M_max=2048,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  M_ratio: {test_env.M_ratio}\")\n",
    "print(f\"  M_min: {test_env.M_min}\")\n",
    "print(f\"  M_max: {test_env.M_max}\")\n",
    "\n",
    "# Test space dimensions\n",
    "expected_obs_dim = 6 + 2048 * 4\n",
    "expected_action_dim = 2048\n",
    "actual_obs_dim = test_env.observation_space.shape[0]\n",
    "actual_action_dim = test_env.action_space.shape[0]\n",
    "\n",
    "print(f\"\\nSpace Dimensions:\")\n",
    "print(f\"  Observation: {actual_obs_dim} (expected: {expected_obs_dim})\")\n",
    "print(f\"  Action: {actual_action_dim} (expected: {expected_action_dim})\")\n",
    "\n",
    "if actual_obs_dim == expected_obs_dim and actual_action_dim == expected_action_dim:\n",
    "    print(\"  ‚úÖ Space dimensions correct!\")\n",
    "else:\n",
    "    print(\"  ‚ùå ERROR: Space dimensions mismatch!\")\n",
    "\n",
    "# Test M calculation for different queue sizes\n",
    "test_cases = [\n",
    "    (100, 512),    # Small queue ‚Üí M_min\n",
    "    (5000, 500),   # Medium queue ‚Üí 10%\n",
    "    (10000, 1000), # Large queue ‚Üí 10%\n",
    "    (25000, 2048), # Very large ‚Üí M_max\n",
    "]\n",
    "\n",
    "print(f\"\\nM Calculation Test:\")\n",
    "print(f\"  Queue Size | Calculated M | Expected M | Status\")\n",
    "print(f\"  {'-'*55}\")\n",
    "\n",
    "all_correct = True\n",
    "for queue_size, expected_M in test_cases:\n",
    "    calculated_M = test_env._get_M(queue_size)\n",
    "    status = \"‚úì\" if calculated_M == expected_M else \"‚úó\"\n",
    "    if calculated_M != expected_M:\n",
    "        all_correct = False\n",
    "    print(f\"  {queue_size:10d} | {calculated_M:12d} | {expected_M:10d} | {status}\")\n",
    "\n",
    "if all_correct:\n",
    "    print(\"\\n‚úÖ VERIFICATION 1 PASSED: Adaptive M system working correctly!\")\n",
    "else:\n",
    "    print(\"\\n‚ùå VERIFICATION 1 FAILED: Check M calculation logic!\")\n",
    "\n",
    "test_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.2: Verify Stochastic Work Duration\n",
    "print(\"=\"*70)\n",
    "print(\"VERIFICATION 2: STOCHASTIC WORK DURATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create stochastic and deterministic environments\n",
    "env_stochastic = RLEnv(\n",
    "    region_key=\"Mataram\",\n",
    "    stochastic_duration=True,\n",
    "    observation_noise=0.0,\n",
    "    capacity_noise=0.0,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "env_deterministic = RLEnv(\n",
    "    region_key=\"Mataram\",\n",
    "    stochastic_duration=False,\n",
    "    observation_noise=0.0,\n",
    "    capacity_noise=0.0,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Reset and advance to day with capacity\n",
    "env_stochastic.reset(seed=100)\n",
    "env_deterministic.reset(seed=100)\n",
    "\n",
    "for _ in range(37):\n",
    "    env_stochastic.step(env_stochastic.action_space.sample())\n",
    "    env_deterministic.step(env_deterministic.action_space.sample())\n",
    "\n",
    "# Test work progress variance\n",
    "test_houses = list(env_stochastic.waiting_queue.get_all())[:5]\n",
    "initial_work_s = [env_stochastic._arr_rem[h] for h in test_houses]\n",
    "initial_work_d = [env_deterministic._arr_rem[h] for h in test_houses]\n",
    "\n",
    "allocation = {h: 10 for h in test_houses}\n",
    "env_stochastic._apply_work(allocation)\n",
    "env_deterministic._apply_work(allocation)\n",
    "\n",
    "progress_s = [initial_work_s[i] - env_stochastic._arr_rem[test_houses[i]] for i in range(5)]\n",
    "progress_d = [initial_work_d[i] - env_deterministic._arr_rem[test_houses[i]] for i in range(5)]\n",
    "\n",
    "print(f\"\\nWork Progress Test (10 workers per house):\")\n",
    "print(f\"  House | Expected | Stochastic | Deterministic\")\n",
    "print(f\"  {'-'*50}\")\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"  {test_houses[i]:5d} | {10:8.2f} | {progress_s[i]:10.2f} | {progress_d[i]:13.2f}\")\n",
    "\n",
    "variance_s = np.var(progress_s)\n",
    "variance_d = np.var(progress_d)\n",
    "\n",
    "print(f\"\\nVariance:\")\n",
    "print(f\"  Stochastic: {variance_s:.4f}\")\n",
    "print(f\"  Deterministic: {variance_d:.4f}\")\n",
    "\n",
    "if abs(variance_d) < 0.01 and variance_s > variance_d:\n",
    "    print(\"\\n‚úÖ VERIFICATION 2 PASSED: Stochastic duration working correctly!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  VERIFICATION 2 WARNING: Check variance values\")\n",
    "\n",
    "env_stochastic.close()\n",
    "env_deterministic.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.3: Verify Observation Noise\n",
    "print(\"=\"*70)\n",
    "print(\"VERIFICATION 3: OBSERVATION NOISE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "env_noisy = RLEnv(\n",
    "    region_key=\"Mataram\",\n",
    "    stochastic_duration=False,\n",
    "    observation_noise=0.15,\n",
    "    capacity_noise=0.0,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "env_perfect = RLEnv(\n",
    "    region_key=\"Mataram\",\n",
    "    stochastic_duration=False,\n",
    "    observation_noise=0.0,\n",
    "    capacity_noise=0.0,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "obs_noisy, _ = env_noisy.reset(seed=100)\n",
    "obs_perfect, _ = env_perfect.reset(seed=100)\n",
    "\n",
    "# Extract candidate features\n",
    "candidates_noisy = obs_noisy[6:].reshape(-1, 4)\n",
    "candidates_perfect = obs_perfect[6:].reshape(-1, 4)\n",
    "\n",
    "valid_mask = candidates_noisy[:, 3] > 0.5\n",
    "remain_noisy = candidates_noisy[valid_mask, 0][:10]\n",
    "remain_perfect = candidates_perfect[valid_mask, 0][:10]\n",
    "\n",
    "print(f\"\\nObservation Noise Test (first 10 valid candidates):\")\n",
    "print(f\"  Candidate | Perfect Info | Noisy Obs | Difference | Noise %\")\n",
    "print(f\"  {'-'*70}\")\n",
    "\n",
    "differences = []\n",
    "for i in range(min(10, len(remain_noisy))):\n",
    "    perfect = remain_perfect[i]\n",
    "    noisy = remain_noisy[i]\n",
    "    diff = noisy - perfect\n",
    "    noise_pct = (diff / perfect * 100) if perfect > 0 else 0\n",
    "    print(f\"  {i:9d} | {perfect:12.2f} | {noisy:9.2f} | {diff:+10.2f} | {noise_pct:+7.1f}%\")\n",
    "    differences.append(abs(diff))\n",
    "\n",
    "avg_diff = np.mean(differences)\n",
    "print(f\"\\nAverage absolute difference: {avg_diff:.2f}\")\n",
    "\n",
    "if avg_diff > 1.0:\n",
    "    print(\"\\n‚úÖ VERIFICATION 3 PASSED: Observation noise detected!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  VERIFICATION 3 WARNING: Noise might be too small\")\n",
    "\n",
    "env_noisy.close()\n",
    "env_perfect.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.4: Verify Capacity Noise\n",
    "print(\"=\"*70)\n",
    "print(\"VERIFICATION 4: CAPACITY NOISE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "env_noisy = RLEnv(\n",
    "    region_key=\"Mataram\",\n",
    "    stochastic_duration=False,\n",
    "    observation_noise=0.0,\n",
    "    capacity_noise=0.10,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "env_perfect = RLEnv(\n",
    "    region_key=\"Mataram\",\n",
    "    stochastic_duration=False,\n",
    "    observation_noise=0.0,\n",
    "    capacity_noise=0.0,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "env_noisy.reset(seed=100)\n",
    "env_perfect.reset(seed=100)\n",
    "\n",
    "# Advance to day 100\n",
    "for _ in range(100):\n",
    "    env_noisy.step(env_noisy.action_space.sample())\n",
    "    env_perfect.step(env_perfect.action_space.sample())\n",
    "\n",
    "# Record capacities\n",
    "capacities_noisy = []\n",
    "capacities_perfect = []\n",
    "\n",
    "for _ in range(50):\n",
    "    capacities_noisy.append(env_noisy._effective_capacity())\n",
    "    capacities_perfect.append(env_perfect._effective_capacity())\n",
    "    env_noisy.step(env_noisy.action_space.sample())\n",
    "    env_perfect.step(env_perfect.action_space.sample())\n",
    "\n",
    "base_capacity = capacities_perfect[0]\n",
    "mean_noisy = np.mean(capacities_noisy)\n",
    "std_noisy = np.std(capacities_noisy)\n",
    "min_noisy = np.min(capacities_noisy)\n",
    "max_noisy = np.max(capacities_noisy)\n",
    "\n",
    "print(f\"\\nCapacity Statistics (50 days):\")\n",
    "print(f\"  Base capacity (perfect): {base_capacity}\")\n",
    "print(f\"  Noisy capacity mean: {mean_noisy:.2f}\")\n",
    "print(f\"  Noisy capacity std dev: {std_noisy:.2f}\")\n",
    "print(f\"  Noisy capacity range: [{min_noisy}, {max_noisy}]\")\n",
    "print(f\"  Expected range: [{int(base_capacity * 0.90)}, {base_capacity}]\")\n",
    "\n",
    "if std_noisy > 0:\n",
    "    print(\"\\n‚úÖ VERIFICATION 4 PASSED: Capacity noise detected!\")\n",
    "else:\n",
    "    print(\"\\n‚ùå VERIFICATION 4 FAILED: No capacity variance!\")\n",
    "\n",
    "env_noisy.close()\n",
    "env_perfect.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.5: Verify Long-term Reward Components\n",
    "print(\"=\"*70)\n",
    "print(\"VERIFICATION 5: LONG-TERM REWARD FUNCTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "env_longterm = RLEnv(\n",
    "    region_key=\"Mataram\",\n",
    "    use_longterm_reward=True,\n",
    "    stochastic_duration=False,\n",
    "    observation_noise=0.0,\n",
    "    capacity_noise=0.0,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "env_legacy = RLEnv(\n",
    "    region_key=\"Mataram\",\n",
    "    use_longterm_reward=False,\n",
    "    stochastic_duration=False,\n",
    "    observation_noise=0.0,\n",
    "    capacity_noise=0.0,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "env_longterm.reset(seed=100)\n",
    "env_legacy.reset(seed=100)\n",
    "\n",
    "# Advance to active phase\n",
    "for _ in range(50):\n",
    "    env_longterm.step(env_longterm.action_space.sample())\n",
    "    env_legacy.step(env_legacy.action_space.sample())\n",
    "\n",
    "# Take one step and compare rewards\n",
    "_, r_long, _, _, info_long = env_longterm.step(env_longterm.action_space.sample())\n",
    "_, r_legacy, _, _, info_legacy = env_legacy.step(env_legacy.action_space.sample())\n",
    "\n",
    "print(f\"\\nReward Comparison (single step):\")\n",
    "print(f\"  Long-term reward: {r_long:.6f}\")\n",
    "print(f\"  Legacy reward: {r_legacy:.6f}\")\n",
    "print(f\"  Difference: {abs(r_long - r_legacy):.6f}\")\n",
    "\n",
    "print(f\"\\nLong-term Reward Components:\")\n",
    "print(f\"  - Completion reward (weight 1.0)\")\n",
    "print(f\"  - Queue reduction bonus (weight 0.2)\")\n",
    "print(f\"  - Urgency penalty (weight 0.1)\")\n",
    "print(f\"  - Worker efficiency bonus (weight 0.05)\")\n",
    "print(f\"  - NO damage weighting (equal treatment)\")\n",
    "\n",
    "print(f\"\\nCurrent State:\")\n",
    "print(f\"  Queue size: {info_long.get('queue_size', 0)}\")\n",
    "print(f\"  Completion: {info_long.get('completion', 0):.4f}\")\n",
    "print(f\"  Max waiting time: {np.max(env_longterm.waiting_time) if len(env_longterm.waiting_time) > 0 else 0} days\")\n",
    "\n",
    "print(\"\\n‚úÖ VERIFICATION 5 PASSED: Long-term reward function implemented!\")\n",
    "\n",
    "env_longterm.close()\n",
    "env_legacy.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.6: Verify Baseline Policies (LJF/SJF)\n",
    "print(\"=\"*70)\n",
    "print(\"VERIFICATION 6: BASELINE POLICIES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for policy_name in [\"LJF\", \"SJF\", \"Random\"]:\n",
    "    print(f\"\\nTesting {policy_name} policy...\")\n",
    "    \n",
    "    env = BaselineEnv(\n",
    "        region_key=\"Mataram\",\n",
    "        policy=policy_name,\n",
    "        M_ratio=0.10,\n",
    "        M_min=512,\n",
    "        M_max=2048,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    obs, info = env.reset(seed=100)\n",
    "    \n",
    "    # Run 10 steps\n",
    "    completions = []\n",
    "    for step in range(10):\n",
    "        obs, reward, done, trunc, info = env.step()\n",
    "        completions.append(info.get('completion', 0))\n",
    "        if done or trunc:\n",
    "            break\n",
    "    \n",
    "    print(f\"  Completed {len(completions)} steps\")\n",
    "    print(f\"  Final completion: {completions[-1]:.4f}\")\n",
    "    print(f\"  ‚úÖ {policy_name} policy works correctly\")\n",
    "    \n",
    "    env.close()\n",
    "\n",
    "print(\"\\n‚úÖ VERIFICATION 6 PASSED: All baseline policies working!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.7: Verify Completion Calculation Consistency\n",
    "print(\"=\"*70)\n",
    "print(\"VERIFICATION 7: COMPLETION CALCULATION CONSISTENCY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "env = RLEnv(region_key=\"Mataram\", seed=42)\n",
    "env.reset(seed=100)\n",
    "\n",
    "# Advance to day 100\n",
    "for _ in range(100):\n",
    "    obs, reward, done, trunc, info = env.step(env.action_space.sample())\n",
    "    if done or trunc:\n",
    "        break\n",
    "\n",
    "# Manual completion calculation\n",
    "revealed_ids = list(env.arrival_system.revealed_ids)\n",
    "completed_manual = sum(1 for h in revealed_ids if env._arr_rem[h] <= 0)\n",
    "completion_manual = completed_manual / len(revealed_ids) if revealed_ids else 0\n",
    "\n",
    "# Info completion\n",
    "completion_info = info.get('completion', 0)\n",
    "\n",
    "print(f\"\\nCompletion Calculation:\")\n",
    "print(f\"  Revealed houses: {len(revealed_ids)}\")\n",
    "print(f\"  Completed houses (manual count): {completed_manual}\")\n",
    "print(f\"  Manual completion: {completion_manual:.6f}\")\n",
    "print(f\"  Info completion: {completion_info:.6f}\")\n",
    "print(f\"  Difference: {abs(completion_manual - completion_info):.6f}\")\n",
    "\n",
    "if abs(completion_manual - completion_info) < 1e-6:\n",
    "    print(\"\\n‚úÖ VERIFICATION 7 PASSED: Completion calculation consistent!\")\n",
    "else:\n",
    "    print(\"\\n‚ùå VERIFICATION 7 FAILED: Completion calculation mismatch!\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.8: Verify Batch Arrival System\n",
    "print(\"=\"*70)\n",
    "print(\"VERIFICATION 8: BATCH ARRIVAL SYSTEM\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "env = RLEnv(\n",
    "    region_key=\"Mataram\",\n",
    "    use_batch_arrival=True,\n",
    "    seed=42\n",
    ")\n",
    "env.reset(seed=100)\n",
    "\n",
    "# Expected batch days: [0, 21, 36]\n",
    "# Expected ratios: [0.40, 0.35, 0.25]\n",
    "\n",
    "batch_days = [0, 21, 36]\n",
    "revealed_counts = []\n",
    "\n",
    "for day in batch_days:\n",
    "    # Advance to batch day\n",
    "    while env.day < day:\n",
    "        env.step(env.action_space.sample())\n",
    "    \n",
    "    revealed = len(env.arrival_system.revealed_ids)\n",
    "    revealed_counts.append(revealed)\n",
    "    print(f\"\\nDay {day}: {revealed} houses revealed\")\n",
    "\n",
    "# Check proportions\n",
    "total_houses = len(env.tasks_df)\n",
    "expected_counts = [int(total_houses * r) for r in [0.40, 0.35, 0.25]]\n",
    "\n",
    "print(f\"\\nBatch Arrival Analysis:\")\n",
    "print(f\"  Total houses: {total_houses}\")\n",
    "print(f\"  Day | Revealed | Expected | Ratio\")\n",
    "print(f\"  {'-'*45}\")\n",
    "\n",
    "for i, day in enumerate(batch_days):\n",
    "    ratio = revealed_counts[i] / total_houses\n",
    "    print(f\"  {day:3d} | {revealed_counts[i]:8d} | {expected_counts[i]:8d} | {ratio:.2%}\")\n",
    "\n",
    "print(\"\\n‚úÖ VERIFICATION 8 PASSED: Batch arrival working!\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.9: Verify Capacity Ramp System\n",
    "print(\"=\"*70)\n",
    "print(\"VERIFICATION 9: CAPACITY RAMP SYSTEM\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "env = RLEnv(\n",
    "    region_key=\"Mataram\",\n",
    "    use_capacity_ramp=True,\n",
    "    capacity_noise=0.0,  # Disable noise for clean test\n",
    "    seed=42\n",
    ")\n",
    "env.reset(seed=100)\n",
    "\n",
    "# Expected: warmup_days=36, rise_days=180, full_capacity_day=216\n",
    "# Days 0-36: K=0\n",
    "# Days 36-216: K grows linearly\n",
    "# Days 216+: K=max\n",
    "\n",
    "test_days = [0, 10, 35, 36, 100, 150, 216, 250]\n",
    "\n",
    "print(f\"\\nCapacity Ramp Test:\")\n",
    "print(f\"  Day | Capacity | Phase\")\n",
    "print(f\"  {'-'*40}\")\n",
    "\n",
    "for day in test_days:\n",
    "    # Advance to test day\n",
    "    while env.day < day:\n",
    "        env.step(env.action_space.sample())\n",
    "    \n",
    "    capacity = env._effective_capacity()\n",
    "    \n",
    "    if day < 36:\n",
    "        phase = \"Warmup (K=0)\"\n",
    "        expected = 0\n",
    "    elif day < 216:\n",
    "        phase = \"Ramp (K growing)\"\n",
    "        expected = \"Growing\"\n",
    "    else:\n",
    "        phase = \"Full capacity\"\n",
    "        expected = \"Max\"\n",
    "    \n",
    "    print(f\"  {day:3d} | {capacity:8d} | {phase}\")\n",
    "\n",
    "print(\"\\n‚úÖ VERIFICATION 9 PASSED: Capacity ramp working!\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.10: Load and Verify Training Data\n",
    "print(\"=\"*70)\n",
    "print(\"VERIFICATION 10: TRAINING DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load synthetic training dataset\n",
    "training_df = pd.read_csv('results/synthetic_training_dataset.csv')\n",
    "\n",
    "print(f\"\\nTraining Dataset Summary:\")\n",
    "print(f\"  Total regions: {len(training_df)}\")\n",
    "print(f\"  Cluster distribution:\")\n",
    "print(training_df.groupby('cluster').size())\n",
    "\n",
    "print(f\"\\nSize Statistics:\")\n",
    "print(f\"  Min: {training_df['total_houses'].min()}\")\n",
    "print(f\"  Max: {training_df['total_houses'].max()}\")\n",
    "print(f\"  Mean: {training_df['total_houses'].mean():.0f}\")\n",
    "print(f\"  Std: {training_df['total_houses'].std():.0f}\")\n",
    "\n",
    "print(f\"\\nDamage Distribution (first 5 regions):\")\n",
    "print(training_df[['region_key', 'total_houses', 'cluster']].head())\n",
    "\n",
    "if len(training_df) == 150:\n",
    "    print(\"\\n‚úÖ VERIFICATION 10 PASSED: Training data loaded correctly!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  WARNING: Expected 150 regions, found {len(training_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: SAC Training\n",
    "\n",
    "Now that all mechanisms are verified, we train the SAC model on diverse synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.1: Define Environment Factory\n",
    "def make_diverse_training_env(rank: int, seed: int):\n",
    "    \"\"\"\n",
    "    Create training environment that samples from diverse synthetic regions.\n",
    "    Each episode uses a different random region.\n",
    "    \"\"\"\n",
    "    # Load training dataset\n",
    "    df = pd.read_csv('results/synthetic_training_dataset.csv')\n",
    "    region_keys = df['region_key'].tolist()\n",
    "    \n",
    "    def _init():\n",
    "        rng = np.random.default_rng(seed + rank)\n",
    "        \n",
    "        # Randomly select a region for this episode\n",
    "        region_key = rng.choice(region_keys)\n",
    "        \n",
    "        env = RLEnv(\n",
    "            region_key=region_key,\n",
    "            M_ratio=0.10,\n",
    "            M_min=512,\n",
    "            M_max=2048,\n",
    "            use_batch_arrival=True,\n",
    "            use_capacity_ramp=True,\n",
    "            stochastic_duration=True,\n",
    "            observation_noise=0.15,\n",
    "            capacity_noise=0.10,\n",
    "            use_longterm_reward=True,\n",
    "            seed=seed + rank * 1000\n",
    "        )\n",
    "        \n",
    "        return Monitor(env)\n",
    "    \n",
    "    return _init\n",
    "\n",
    "print(\"‚úÖ Environment factory defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.2: Create Vectorized Training Environment\n",
    "print(\"=\"*70)\n",
    "print(\"CREATING VECTORIZED TRAINING ENVIRONMENT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# Configuration\n",
    "N_ENVS = 8\n",
    "SEED = 42\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Number of environments: {N_ENVS}\")\n",
    "print(f\"  Base seed: {SEED}\")\n",
    "print(f\"  Using: DummyVecEnv (single-process for notebook stability)\")\n",
    "\n",
    "# Load training dataset (in case Cell 3.1 wasn't run)\n",
    "try:\n",
    "    # Check if df exists from Cell 3.1\n",
    "    if 'df' not in globals():\n",
    "        print(f\"\\nLoading training dataset...\")\n",
    "        df = pd.read_csv('results/synthetic_training_dataset.csv')\n",
    "        \n",
    "        # Register all synthetic regions\n",
    "        from config import register_synthetic_region\n",
    "        \n",
    "        print(f\"Registering {len(df)} synthetic regions...\")\n",
    "        for idx, row in df.iterrows():\n",
    "            register_synthetic_region(\n",
    "                H=int(row['total_houses']),\n",
    "                K=int(row['num_contractors']),\n",
    "                damage_dist=[\n",
    "                    int(row['minor_count']),\n",
    "                    int(row['moderate_count']),\n",
    "                    int(row['major_count'])\n",
    "                ],\n",
    "                seed=int(row['seed'])\n",
    "            )\n",
    "        print(f\"‚úÖ All {len(df)} regions registered!\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ Using {len(df)} regions from Cell 3.1\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading training data: {e}\")\n",
    "    raise\n",
    "\n",
    "# Define environment factory\n",
    "def make_training_env(rank: int):\n",
    "    \"\"\"Create a single training environment\"\"\"\n",
    "    def _init():\n",
    "        rng = np.random.default_rng(SEED + rank)\n",
    "        \n",
    "        # Randomly select a region (regions already registered)\n",
    "        region_key = rng.choice(df['region_key'].tolist())\n",
    "        \n",
    "        env = RLEnv(\n",
    "            region_key=region_key,\n",
    "            M_ratio=0.10,\n",
    "            M_min=512,\n",
    "            M_max=2048,\n",
    "            use_batch_arrival=True,\n",
    "            use_capacity_ramp=True,\n",
    "            stochastic_duration=True,\n",
    "            observation_noise=0.15,\n",
    "            capacity_noise=0.10,\n",
    "            use_longterm_reward=True,\n",
    "            seed=SEED + rank * 1000\n",
    "        )\n",
    "        \n",
    "        return Monitor(env)\n",
    "    \n",
    "    return _init\n",
    "\n",
    "# Create vectorized environment\n",
    "print(f\"\\nCreating {N_ENVS} environments...\")\n",
    "try:\n",
    "    env_fns = [make_training_env(i) for i in range(N_ENVS)]\n",
    "    vec_env = DummyVecEnv(env_fns)\n",
    "    print(\"‚úÖ DummyVecEnv created\")\n",
    "    \n",
    "    vec_env = VecMonitor(vec_env)\n",
    "    print(\"‚úÖ VecMonitor wrapped\")\n",
    "    \n",
    "    vec_env = VecNormalize(\n",
    "        vec_env,\n",
    "        norm_obs=True,\n",
    "        norm_reward=True,\n",
    "        clip_obs=10.0,\n",
    "        clip_reward=10.0,\n",
    "        gamma=0.99\n",
    "    )\n",
    "    print(\"‚úÖ VecNormalize wrapped\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Vectorized environment ready!\")\n",
    "    print(f\"   Observation space: {vec_env.observation_space.shape}\")\n",
    "    print(f\"   Action space: {vec_env.action_space.shape}\")\n",
    "    \n",
    "    print(f\"\\nüìù Notes:\")\n",
    "    print(f\"   - DummyVecEnv is single-process (more stable in notebooks)\")\n",
    "    print(f\"   - Training will be slower than SubprocVecEnv but reliable\")\n",
    "    print(f\"   - For faster training, use: python train_sac_script.py\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error creating vectorized environment:\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.3: Create SAC Model\n",
    "print(\"=\"*70)\n",
    "print(\"CREATING SAC MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "model = SAC(\n",
    "    \"MlpPolicy\",\n",
    "    vec_env,\n",
    "    learning_rate=3e-4,\n",
    "    buffer_size=500_000,\n",
    "    batch_size=512,\n",
    "    tau=0.005,\n",
    "    gamma=0.99,\n",
    "    train_freq=1,\n",
    "    gradient_steps=1,\n",
    "    ent_coef='auto',\n",
    "    target_update_interval=1,\n",
    "    verbose=1,\n",
    "    tensorboard_log=\"./runs/sac_diverse/\",\n",
    "    device='auto'\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ SAC model created successfully!\")\n",
    "print(f\"\\nModel Configuration:\")\n",
    "print(f\"  Policy: MlpPolicy\")\n",
    "print(f\"  Learning rate: 3e-4\")\n",
    "print(f\"  Buffer size: 500,000\")\n",
    "print(f\"  Batch size: 512\")\n",
    "print(f\"  Gamma: 0.99\")\n",
    "print(f\"  Entropy coefficient: auto\")\n",
    "print(f\"  Device: {model.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.4: Setup Training Callbacks\n",
    "print(\"=\"*70)\n",
    "print(\"SETTING UP TRAINING CALLBACKS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Checkpoint callback - save model every 50k steps\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "    save_freq=50_000 // N_ENVS,  # Adjust for parallel envs\n",
    "    save_path='./models/checkpoints/',\n",
    "    name_prefix='sac_diverse',\n",
    "    verbose=1\n",
    ")\n",
    "print(\"‚úÖ Checkpoint callback configured (every 50k steps)\")\n",
    "\n",
    "callbacks = [checkpoint_callback]\n",
    "\n",
    "print(f\"\\n‚úÖ {len(callbacks)} callback(s) ready for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.5: Train SAC Model\n",
    "print(\"=\"*70)\n",
    "print(\"STARTING SAC TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "TOTAL_TIMESTEPS = 500_000\n",
    "\n",
    "print(f\"\\nTraining Configuration:\")\n",
    "print(f\"  Total timesteps: {TOTAL_TIMESTEPS:,}\")\n",
    "print(f\"  Parallel environments: {N_ENVS}\")\n",
    "print(f\"  Estimated episodes: ~{TOTAL_TIMESTEPS // 500} (assuming ~500 steps/episode)\")\n",
    "print(f\"  Tensorboard log: ./runs/sac_diverse/\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"TRAINING IN PROGRESS...\")\n",
    "print(f\"{'='*70}\")\n",
    "print(\"\\nTo monitor training:\")\n",
    "print(\"  tensorboard --logdir ./runs/sac_diverse/\")\n",
    "print()\n",
    "\n",
    "# Start training\n",
    "model.learn(\n",
    "    total_timesteps=TOTAL_TIMESTEPS,\n",
    "    callback=callbacks,\n",
    "    progress_bar=True\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"‚úÖ TRAINING COMPLETED!\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.6: Save Trained Model\n",
    "print(\"=\"*70)\n",
    "print(\"SAVING TRAINED MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save model\n",
    "model.save(\"models/sac_diverse_final\")\n",
    "print(\"‚úÖ Model saved: models/sac_diverse_final.zip\")\n",
    "\n",
    "# Save VecNormalize statistics\n",
    "vec_env.save(\"models/sac_diverse_vecnorm.pkl\")\n",
    "print(\"‚úÖ VecNormalize stats saved: models/sac_diverse_vecnorm.pkl\")\n",
    "\n",
    "print(\"\\n‚úÖ All training artifacts saved successfully!\")\n",
    "print(\"\\nSaved files:\")\n",
    "print(\"  - models/sac_diverse_final.zip\")\n",
    "print(\"  - models/sac_diverse_vecnorm.pkl\")\n",
    "print(\"  - models/checkpoints/sac_diverse_*.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Cross-Scenario Evaluation\n",
    "\n",
    "Evaluate the trained model across different regions and crew availability levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4.1: Load Trained Model\n",
    "print(\"=\"*70)\n",
    "print(\"LOADING TRAINED MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load SAC model\n",
    "sac_model = SAC.load(\"models/sac_diverse_final\")\n",
    "print(\"‚úÖ SAC model loaded\")\n",
    "\n",
    "# Note: VecNormalize stats not needed for evaluation since we evaluate on raw environment\n",
    "\n",
    "print(\"\\n‚úÖ Model ready for evaluation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4.2: Run Cross-Scenario Evaluation\n",
    "print(\"=\"*70)\n",
    "print(\"CROSS-SCENARIO EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def evaluate_single_run(model, policy_name, region, crew_availability, seed, max_days=500):\n",
    "    \"\"\"Run single evaluation episode\"\"\"\n",
    "    # Get base crew count\n",
    "    base_crew = REGION_CONFIG[region]['num_contractors']\n",
    "    actual_crew = int(base_crew * crew_availability)\n",
    "    \n",
    "    # Create environment\n",
    "    if policy_name in ['SAC']:\n",
    "        env = RLEnv(\n",
    "            region_key=region,\n",
    "            num_contractors=actual_crew,\n",
    "            M_ratio=0.10,\n",
    "            M_min=512,\n",
    "            M_max=2048,\n",
    "            use_batch_arrival=True,\n",
    "            use_capacity_ramp=True,\n",
    "            stochastic_duration=True,\n",
    "            observation_noise=0.15,\n",
    "            capacity_noise=0.10,\n",
    "            use_longterm_reward=True,\n",
    "            seed=seed\n",
    "        )\n",
    "    else:\n",
    "        env = BaselineEnv(\n",
    "            region_key=region,\n",
    "            policy=policy_name,\n",
    "            num_contractors=actual_crew,\n",
    "            use_batch_arrival=True,\n",
    "            use_capacity_ramp=True,\n",
    "            seed=seed\n",
    "        )\n",
    "    \n",
    "    # Run episode\n",
    "    obs, info = env.reset()\n",
    "    trajectory = []\n",
    "    \n",
    "    for step in range(max_days):\n",
    "        if policy_name == 'SAC':\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "        else:\n",
    "            action = None\n",
    "        \n",
    "        obs, reward, done, trunc, info = env.step(action)\n",
    "        trajectory.append(info.get('completion', 0))\n",
    "        \n",
    "        if done or trunc:\n",
    "            break\n",
    "    \n",
    "    env.close()\n",
    "    \n",
    "    # Extract metrics\n",
    "    final_completion = trajectory[-1] if trajectory else 0.0\n",
    "    makespan = next((i for i, c in enumerate(trajectory) if c >= 0.99), max_days)\n",
    "    \n",
    "    return {\n",
    "        'policy': policy_name,\n",
    "        'region': region,\n",
    "        'crew_availability': crew_availability,\n",
    "        'seed': seed,\n",
    "        'final_completion': final_completion,\n",
    "        'makespan': makespan,\n",
    "        'trajectory': trajectory\n",
    "    }\n",
    "\n",
    "# Evaluation configuration\n",
    "test_regions = [\"Mataram\", \"Sumbawa\", \"Central Lombok\"]\n",
    "crew_levels = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0]\n",
    "policies = {'SAC': sac_model, 'LJF': None, 'SJF': None, 'Random': None}\n",
    "n_seeds = 5\n",
    "base_seed = 1000\n",
    "\n",
    "total_runs = len(policies) * len(test_regions) * len(crew_levels) * n_seeds\n",
    "print(f\"\\nEvaluation Configuration:\")\n",
    "print(f\"  Test regions: {test_regions}\")\n",
    "print(f\"  Crew levels: {crew_levels}\")\n",
    "print(f\"  Policies: {list(policies.keys())}\")\n",
    "print(f\"  Seeds per condition: {n_seeds}\")\n",
    "print(f\"  Total runs: {total_runs}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"RUNNING EVALUATION...\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "results = []\n",
    "current_run = 0\n",
    "\n",
    "for policy_name, model_obj in policies.items():\n",
    "    for region in test_regions:\n",
    "        for crew_level in crew_levels:\n",
    "            for seed_offset in range(n_seeds):\n",
    "                seed = base_seed + seed_offset\n",
    "                current_run += 1\n",
    "                \n",
    "                if current_run % 10 == 0 or current_run == total_runs:\n",
    "                    print(f\"[{current_run}/{total_runs}] {policy_name:8s} | {region:20s} | Crew={crew_level:.1f}\")\n",
    "                \n",
    "                result = evaluate_single_run(\n",
    "                    model_obj, policy_name, region, crew_level, seed\n",
    "                )\n",
    "                results.append(result)\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame([\n",
    "    {k: v for k, v in r.items() if k != 'trajectory'}\n",
    "    for r in results\n",
    "])\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv('results/cross_scenario_results.csv', index=False)\n",
    "print(f\"\\n‚úÖ Evaluation complete! Results saved to: results/cross_scenario_results.csv\")\n",
    "\n",
    "# Quick summary\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"QUICK SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "summary = results_df.groupby('policy')['final_completion'].agg(['mean', 'std'])\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Validation & Visualization\n",
    "\n",
    "Analyze results and generate comprehensive visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5.1: Summary Statistics\n",
    "print(\"=\"*70)\n",
    "print(\"DETAILED SUMMARY STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results_df = pd.read_csv('results/cross_scenario_results.csv')\n",
    "\n",
    "print(f\"\\nOverall Performance by Policy:\")\n",
    "summary = results_df.groupby('policy')['final_completion'].agg([\n",
    "    'mean', 'std', 'min', 'max'\n",
    "])\n",
    "summary['cv'] = summary['std'] / summary['mean']  # Coefficient of variation\n",
    "summary = summary.sort_values('mean', ascending=False)\n",
    "print(summary)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Performance by Region:\")\n",
    "print(f\"{'='*70}\")\n",
    "for region in results_df['region'].unique():\n",
    "    print(f\"\\n{region}:\")\n",
    "    region_summary = results_df[results_df['region'] == region].groupby('policy')['final_completion'].mean()\n",
    "    region_summary = region_summary.sort_values(ascending=False)\n",
    "    print(region_summary)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Crew Sensitivity Analysis:\")\n",
    "print(f\"{'='*70}\")\n",
    "for policy in results_df['policy'].unique():\n",
    "    policy_df = results_df[results_df['policy'] == policy]\n",
    "    comp_10 = policy_df[policy_df['crew_availability'] == 0.1]['final_completion'].mean()\n",
    "    comp_100 = policy_df[policy_df['crew_availability'] == 1.0]['final_completion'].mean()\n",
    "    drop = comp_100 - comp_10\n",
    "    drop_pct = (drop / comp_100) * 100 if comp_100 > 0 else 0\n",
    "    print(f\"{policy:10s}: {comp_100:.2%} ‚Üí {comp_10:.2%} (drop: {drop_pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5.2: Generate Heatmap\n",
    "print(\"=\"*70)\n",
    "print(\"GENERATING HEATMAP: Policy √ó Crew Availability\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "pivot = results_df.pivot_table(\n",
    "    values='final_completion',\n",
    "    index='policy',\n",
    "    columns='crew_availability',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(pivot, annot=True, fmt='.2%', cmap='RdYlGn', \n",
    "            vmin=0, vmax=1, cbar_kws={'label': 'Mean Completion'})\n",
    "plt.title('Performance Heatmap: Policy √ó Crew Availability', fontsize=14, pad=20)\n",
    "plt.xlabel('Crew Availability', fontsize=12)\n",
    "plt.ylabel('Policy', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/heatmap_policy_crew.png', dpi=150, bbox_inches='tight')\n",
    "print(\"‚úÖ Saved: results/figures/heatmap_policy_crew.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5.3: Generate Crew Sensitivity Curves\n",
    "print(\"=\"*70)\n",
    "print(\"GENERATING CREW SENSITIVITY CURVES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(results_df['region'].unique()), \n",
    "                         figsize=(6*len(results_df['region'].unique()), 5))\n",
    "\n",
    "if len(results_df['region'].unique()) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "colors = {'SAC': '#1f77b4', 'LJF': '#2ca02c', 'SJF': '#d62728', 'Random': '#9467bd'}\n",
    "\n",
    "for ax, region in zip(axes, results_df['region'].unique()):\n",
    "    region_df = results_df[results_df['region'] == region]\n",
    "    \n",
    "    for policy in region_df['policy'].unique():\n",
    "        policy_df = region_df[region_df['policy'] == policy]\n",
    "        grouped = policy_df.groupby('crew_availability')['final_completion']\n",
    "        means = grouped.mean()\n",
    "        stds = grouped.std()\n",
    "        \n",
    "        ax.plot(means.index, means.values, marker='o', label=policy, \n",
    "                linewidth=2.5, color=colors.get(policy), alpha=0.9)\n",
    "        ax.fill_between(means.index, \n",
    "                        means.values - stds.values,\n",
    "                        means.values + stds.values,\n",
    "                        alpha=0.2, color=colors.get(policy))\n",
    "    \n",
    "    ax.set_xlabel('Crew Availability', fontsize=12)\n",
    "    ax.set_ylabel('Completion Rate', fontsize=12)\n",
    "    ax.set_title(f'{region}', fontsize=13, fontweight='bold')\n",
    "    ax.legend(fontsize=10, loc='lower right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim(0, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/crew_sensitivity.png', dpi=150, bbox_inches='tight')\n",
    "print(\"‚úÖ Saved: results/figures/crew_sensitivity.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5.4: Generate Robustness Box Plot\n",
    "print(\"=\"*70)\n",
    "print(\"GENERATING ROBUSTNESS BOX PLOT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "results_df.boxplot(column='final_completion', by='policy', ax=plt.gca())\n",
    "plt.title('Performance Robustness Across All Scenarios', fontsize=14, pad=20)\n",
    "plt.suptitle('')  # Remove default title\n",
    "plt.xlabel('Policy', fontsize=12)\n",
    "plt.ylabel('Completion Rate', fontsize=12)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/robustness_boxplot.png', dpi=150, bbox_inches='tight')\n",
    "print(\"‚úÖ Saved: results/figures/robustness_boxplot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5.5: Statistical Significance Tests\n",
    "print(\"=\"*70)\n",
    "print(\"STATISTICAL SIGNIFICANCE TESTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# Pairwise comparisons at crew=1.0\n",
    "crew_100_df = results_df[results_df['crew_availability'] == 1.0]\n",
    "\n",
    "policies = crew_100_df['policy'].unique()\n",
    "\n",
    "print(\"\\nPairwise t-tests (crew=1.0):\")\n",
    "print(f\"{'Policy 1':10s} vs {'Policy 2':10s} | t-stat | p-value | Significant\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for i, policy1 in enumerate(policies):\n",
    "    for policy2 in policies[i+1:]:\n",
    "        data1 = crew_100_df[crew_100_df['policy'] == policy1]['final_completion']\n",
    "        data2 = crew_100_df[crew_100_df['policy'] == policy2]['final_completion']\n",
    "        \n",
    "        t_stat, p_value = stats.ttest_ind(data1, data2)\n",
    "        sig = \"***\" if p_value < 0.001 else (\"**\" if p_value < 0.01 else (\"*\" if p_value < 0.05 else \"ns\"))\n",
    "        \n",
    "        print(f\"{policy1:10s} vs {policy2:10s} | {t_stat:7.3f} | {p_value:7.4f} | {sig}\")\n",
    "\n",
    "print(\"\\nSignificance codes: *** p<0.001, ** p<0.01, * p<0.05, ns=not significant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5.6: Generate Final Summary Report\n",
    "print(\"=\"*70)\n",
    "print(\"FINAL SUMMARY REPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "report = []\n",
    "report.append(\"# HouseGym RL: Evaluation Report\\n\")\n",
    "report.append(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "\n",
    "report.append(\"## Overall Performance\\n\")\n",
    "summary = results_df.groupby('policy')['final_completion'].agg(['mean', 'std', 'min', 'max'])\n",
    "summary['cv'] = summary['std'] / summary['mean']\n",
    "summary = summary.sort_values('mean', ascending=False)\n",
    "report.append(summary.to_string())\n",
    "report.append(\"\\n\\n\")\n",
    "\n",
    "report.append(\"## Best Policy per Region\\n\")\n",
    "for region in results_df['region'].unique():\n",
    "    region_df = results_df[results_df['region'] == region]\n",
    "    best = region_df.groupby('policy')['final_completion'].mean().idxmax()\n",
    "    best_score = region_df.groupby('policy')['final_completion'].mean().max()\n",
    "    report.append(f\"- {region}: {best} ({best_score:.2%})\\n\")\n",
    "report.append(\"\\n\")\n",
    "\n",
    "report.append(\"## Crew Sensitivity\\n\")\n",
    "for policy in results_df['policy'].unique():\n",
    "    policy_df = results_df[results_df['policy'] == policy]\n",
    "    comp_10 = policy_df[policy_df['crew_availability'] == 0.1]['final_completion'].mean()\n",
    "    comp_100 = policy_df[policy_df['crew_availability'] == 1.0]['final_completion'].mean()\n",
    "    drop = comp_100 - comp_10\n",
    "    report.append(f\"- {policy}: {comp_100:.2%} ‚Üí {comp_10:.2%} (drop: {drop:.2%})\\n\")\n",
    "report.append(\"\\n\")\n",
    "\n",
    "report.append(\"## Key Findings\\n\")\n",
    "best_overall = summary.index[0]\n",
    "most_robust = summary.sort_values('cv').index[0]\n",
    "report.append(f\"- Best overall performance: {best_overall}\\n\")\n",
    "report.append(f\"- Most robust (lowest CV): {most_robust}\\n\")\n",
    "report.append(f\"- Total scenarios tested: {len(results_df)}\\n\")\n",
    "\n",
    "# Save report\n",
    "with open('results/evaluation_report.md', 'w') as f:\n",
    "    f.writelines(report)\n",
    "\n",
    "print(\"\\n‚úÖ Report saved: results/evaluation_report.md\")\n",
    "\n",
    "# Print report\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "for line in report:\n",
    "    print(line, end='')\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "print(\"\\n‚úÖ ALL TASKS COMPLETED SUCCESSFULLY!\")\n",
    "print(\"\\nGenerated outputs:\")\n",
    "print(\"  - models/sac_diverse_final.zip\")\n",
    "print(\"  - results/cross_scenario_results.csv\")\n",
    "print(\"  - results/figures/heatmap_policy_crew.png\")\n",
    "print(\"  - results/figures/crew_sensitivity.png\")\n",
    "print(\"  - results/figures/robustness_boxplot.png\")\n",
    "print(\"  - results/evaluation_report.md\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urbanai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
